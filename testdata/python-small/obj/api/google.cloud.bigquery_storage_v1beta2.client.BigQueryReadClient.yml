### YamlMime:UniversalReference
api_name: []
items:
- attributes: []
  children:
  - google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  - google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.__exit__
  - google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.common_billing_account_path
  - google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.common_folder_path
  - google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.common_location_path
  - google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.common_organization_path
  - google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.common_project_path
  - google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.create_read_session
  - google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.from_service_account_file
  - google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.from_service_account_info
  - google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.from_service_account_json
  - google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.get_mtls_endpoint_and_cert_source
  - google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.parse_common_billing_account_path
  - google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.parse_common_folder_path
  - google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.parse_common_location_path
  - google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.parse_common_organization_path
  - google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.parse_common_project_path
  - google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.parse_read_session_path
  - google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.parse_read_stream_path
  - google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.parse_table_path
  - google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.read_rows
  - google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.read_session_path
  - google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.read_stream_path
  - google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.split_read_stream
  - google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.table_path
  - google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.transport
  class: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  inheritance:
  - inheritance:
    - type: builtins.object
    type: google.cloud.bigquery_storage_v1beta2.services.big_query_read.client.BigQueryReadClient
  langs:
  - python
  module: google.cloud.bigquery_storage_v1beta2.client
  name: BigQueryReadClient
  source:
    id: BigQueryReadClient
    path: google/cloud/bigquery_storage_v1beta2/client.py
    remote:
      branch: main
      path: google/cloud/bigquery_storage_v1beta2/client.py
      repo: git@github.com:googleapis/python-bigquery-storage.git
    startLine: 38
  summary: 'Client for interacting with BigQuery Storage API.


    The BigQuery storage API can be used to read data stored in BigQuery.


    '
  syntax:
    content: 'BigQueryReadClient(*, credentials: typing.Optional[google.auth.credentials.Credentials]
      = None, transport: typing.Optional[typing.Union[str, google.cloud.bigquery_storage_v1beta2.services.big_query_read.transports.base.BigQueryReadTransport]]
      = None, client_options: typing.Optional[google.api_core.client_options.ClientOptions]
      = None, client_info: google.api_core.gapic_v1.client_info.ClientInfo = <google.api_core.gapic_v1.client_info.ClientInfo
      object>)'
    parameters: []
  type: class
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
- attributes: []
  class: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  inheritance:
  - inheritance:
    - type: builtins.object
    type: google.cloud.bigquery_storage_v1beta2.services.big_query_read.client.BigQueryReadClient
  langs:
  - python
  module: google.cloud.bigquery_storage_v1beta2.client
  name: BigQueryReadClient
  source:
    id: BigQueryReadClient
    path: google/cloud/bigquery_storage_v1beta2/client.py
    remote:
      branch: main
      path: google/cloud/bigquery_storage_v1beta2/client.py
      repo: git@github.com:googleapis/python-bigquery-storage.git
    startLine: 38
  summary: 'Instantiates the big query read client.

    '
  syntax:
    content: 'BigQueryReadClient(*, credentials: typing.Optional[google.auth.credentials.Credentials]
      = None, transport: typing.Optional[typing.Union[str, google.cloud.bigquery_storage_v1beta2.services.big_query_read.transports.base.BigQueryReadTransport]]
      = None, client_options: typing.Optional[google.api_core.client_options.ClientOptions]
      = None, client_info: google.api_core.gapic_v1.client_info.ClientInfo = <google.api_core.gapic_v1.client_info.ClientInfo
      object>)'
    exceptions:
    - description: If mutual TLS transport creation failed for any reason.
      var_type: google.auth.exceptions.MutualTLSChannelError
    parameters:
    - description: The authorization credentials to attach to requests. These credentials
        identify the application to the service; if none are specified, the client
        will attempt to ascertain the credentials from the environment.
      id: credentials
      var_type: Optional[google.auth.credentials.Credentials]
    - description: The transport to use. If set to None, a transport is chosen automatically.
      id: transport
      var_type: Union[str, BigQueryReadTransport]
    - description: 'Custom options for the client. It won''t take effect if a ``transport``
        instance is provided. (1) The ``api_endpoint`` property can be used to override
        the default endpoint provided by the client. GOOGLE_API_USE_MTLS_ENDPOINT
        environment variable can also be used to override the endpoint: "always" (always
        use the default mTLS endpoint), "never" (always use the default regular endpoint)
        and "auto" (auto switch to the default mTLS endpoint if client certificate
        is present, this is the default value). However, the ``api_endpoint`` property
        takes precedence if provided. (2) If GOOGLE_API_USE_CLIENT_CERTIFICATE environment
        variable is "true", then the ``client_cert_source`` property can be used to
        provide client certificate for mutual TLS transport. If not provided, the
        default SSL client certificate will be used if present. If GOOGLE_API_USE_CLIENT_CERTIFICATE
        is "false" or not set, no client certificate will be used.'
      id: client_options
      var_type: google.api_core.client_options.ClientOptions
    - description: The client info used to send a user-agent string along with API
        requests. If ``None``, then default info will be used. Generally, you only
        need to set this if you're developing your own client library.
      id: client_info
      var_type: google.api_core.gapic_v1.client_info.ClientInfo
  type: method
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
- attributes: []
  class: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.__exit__
  langs:
  - python
  module: google.cloud.bigquery_storage_v1beta2.client
  name: __exit__
  source:
    id: __exit__
    path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
    remote:
      branch: main
      path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
      repo: git@github.com:googleapis/python-bigquery-storage.git
    startLine: 717
  summary: "Releases underlying transport's resources.\n\n.. warning::\n    ONLY use\
    \ as a context manager if the transport is NOT shared\n    with other clients!\
    \ Exiting the with block will CLOSE the transport\n    and may cause errors in\
    \ other clients!\n\n"
  syntax:
    content: __exit__(type, value, traceback)
    parameters: []
  type: method
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.__exit__
- attributes: []
  class: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.common_billing_account_path
  langs:
  - python
  module: google.cloud.bigquery_storage_v1beta2.client
  name: common_billing_account_path
  source:
    id: common_billing_account_path
    path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
    remote:
      branch: main
      path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
      repo: git@github.com:googleapis/python-bigquery-storage.git
    startLine: 217
  summary: 'Returns a fully-qualified billing_account string.


    '
  syntax:
    content: 'common_billing_account_path(billing_account: str)'
    parameters: []
  type: method
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.common_billing_account_path
- attributes: []
  class: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.common_folder_path
  langs:
  - python
  module: google.cloud.bigquery_storage_v1beta2.client
  name: common_folder_path
  source:
    id: common_folder_path
    path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
    remote:
      branch: main
      path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
      repo: git@github.com:googleapis/python-bigquery-storage.git
    startLine: 230
  summary: 'Returns a fully-qualified folder string.


    '
  syntax:
    content: 'common_folder_path(folder: str)'
    parameters: []
  type: method
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.common_folder_path
- attributes: []
  class: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.common_location_path
  langs:
  - python
  module: google.cloud.bigquery_storage_v1beta2.client
  name: common_location_path
  source:
    id: common_location_path
    path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
    remote:
      branch: main
      path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
      repo: git@github.com:googleapis/python-bigquery-storage.git
    startLine: 263
  summary: 'Returns a fully-qualified location string.


    '
  syntax:
    content: 'common_location_path(project: str, location: str)'
    parameters: []
  type: method
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.common_location_path
- attributes: []
  class: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.common_organization_path
  langs:
  - python
  module: google.cloud.bigquery_storage_v1beta2.client
  name: common_organization_path
  source:
    id: common_organization_path
    path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
    remote:
      branch: main
      path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
      repo: git@github.com:googleapis/python-bigquery-storage.git
    startLine: 241
  summary: 'Returns a fully-qualified organization string.


    '
  syntax:
    content: 'common_organization_path(organization: str)'
    parameters: []
  type: method
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.common_organization_path
- attributes: []
  class: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.common_project_path
  langs:
  - python
  module: google.cloud.bigquery_storage_v1beta2.client
  name: common_project_path
  source:
    id: common_project_path
    path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
    remote:
      branch: main
      path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
      repo: git@github.com:googleapis/python-bigquery-storage.git
    startLine: 252
  summary: 'Returns a fully-qualified project string.


    '
  syntax:
    content: 'common_project_path(project: str)'
    parameters: []
  type: method
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.common_project_path
- attributes: []
  class: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.create_read_session
  langs:
  - python
  module: google.cloud.bigquery_storage_v1beta2.client
  name: create_read_session
  source:
    id: create_read_session
    path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
    remote:
      branch: main
      path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
      repo: git@github.com:googleapis/python-bigquery-storage.git
    startLine: 441
  summary: 'Creates a new read session. A read session divides

    the contents of a BigQuery table into one or more

    streams, which can then be used to read data from the

    table. The read session also specifies properties of the

    data to be read, such as a list of columns or a

    push-down filter describing the rows to be returned.


    A particular row can be read by at most one stream. When

    the caller has reached the end of each stream in the

    session, then all the data in the table has been read.


    Data is assigned to each stream such that roughly the

    same number of rows can be read from each stream.

    Because the server-side unit for assigning data is

    collections of rows, the API does not guarantee that

    each stream will return the same number or rows.

    Additionally, the limits are enforced based on the

    number of pre-filtered rows, so some filters can lead to

    lopsided assignments.


    Read sessions automatically expire 6 hours after they

    are created and do not require manual clean-up by the

    caller.

    '
  syntax:
    content: "create_read_session(\n    request: typing.Optional[\n        typing.Union[\n\
      \            google.cloud.bigquery_storage_v1beta2.types.storage.CreateReadSessionRequest,\n\
      \            dict,\n        ]\n    ] = None,\n    *,\n    parent: typing.Optional[str]\
      \ = None,\n    read_session: typing.Optional[\n        google.cloud.bigquery_storage_v1beta2.types.stream.ReadSession\n\
      \    ] = None,\n    max_stream_count: typing.Optional[int] = None,\n    retry:\
      \ typing.Union[\n        google.api_core.retry.Retry, google.api_core.gapic_v1.method._MethodDefault\n\
      \    ] = _MethodDefault._DEFAULT_VALUE,\n    timeout: typing.Optional[float]\
      \ = None,\n    metadata: typing.Sequence[typing.Tuple[str, str]] = ()\n)"
    parameters:
    - defaultValue: None
      description: The request object. Request message for `CreateReadSession`.
      id: request
      var_type: Union[<xref uid="google.cloud.bigquery_storage_v1beta2.types.CreateReadSessionRequest">google.cloud.bigquery_storage_v1beta2.types.CreateReadSessionRequest</xref>,
        dict]
    - description: Required. The request project that owns the session, in the form
        of ``projects/{project_id}``. This corresponds to the ``parent`` field on
        the ``request`` instance; if ``request`` is provided, this should not be set.
      id: parent
      var_type: str
    - description: Required. Session to be created. This corresponds to the ``read_session``
        field on the ``request`` instance; if ``request`` is provided, this should
        not be set.
      id: read_session
      var_type: <xref uid="google.cloud.bigquery_storage_v1beta2.types.ReadSession">google.cloud.bigquery_storage_v1beta2.types.ReadSession</xref>
    - description: Max initial number of streams. If unset or zero, the server will
        provide a value of streams so as to produce reasonable throughput. Must be
        non-negative. The number of streams may be lower than the requested number,
        depending on the amount parallelism that is reasonable for the table. Error
        will be returned if the max count is greater than the current system max limit
        of 1,000. Streams must be read starting from offset 0. This corresponds to
        the ``max_stream_count`` field on the ``request`` instance; if ``request``
        is provided, this should not be set.
      id: max_stream_count
      var_type: int
    - description: Designation of what errors, if any, should be retried.
      id: retry
      var_type: google.api_core.retry.Retry
    - description: The timeout for this request.
      id: timeout
      var_type: float
    - description: Strings which should be sent along with the request as metadata.
      id: metadata
      var_type: Sequence[Tuple[str, str]]
    returns:
    - description: Information about the ReadSession.
      var_type: <xref uid="google.cloud.bigquery_storage_v1beta2.types.ReadSession">google.cloud.bigquery_storage_v1beta2.types.ReadSession</xref>
  type: method
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.create_read_session
- attributes: []
  class: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.from_service_account_file
  langs:
  - python
  module: google.cloud.bigquery_storage_v1beta2.client
  name: from_service_account_file
  source:
    id: from_service_account_file
    path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
    remote:
      branch: main
      path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
      repo: git@github.com:googleapis/python-bigquery-storage.git
    startLine: 137
  summary: "Creates an instance of this client using the provided credentials\n  \
    \  file.\n"
  syntax:
    content: 'from_service_account_file(filename: str, *args, **kwargs)'
    parameters:
    - description: The path to the service account private key json file.
      id: filename
      var_type: str
    returns:
    - description: The constructed client.
      var_type: BigQueryReadClient
  type: method
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.from_service_account_file
- attributes: []
  class: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.from_service_account_info
  langs:
  - python
  module: google.cloud.bigquery_storage_v1beta2.client
  name: from_service_account_info
  source:
    id: from_service_account_info
    path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
    remote:
      branch: main
      path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
      repo: git@github.com:googleapis/python-bigquery-storage.git
    startLine: 120
  summary: "Creates an instance of this client using the provided credentials\n  \
    \  info.\n"
  syntax:
    content: 'from_service_account_info(info: dict, *args, **kwargs)'
    parameters:
    - description: The service account private key info.
      id: info
      var_type: dict
    returns:
    - description: The constructed client.
      var_type: BigQueryReadClient
  type: method
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.from_service_account_info
- attributes: []
  class: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.from_service_account_json
  langs:
  - python
  module: google.cloud.bigquery_storage_v1beta2.client
  name: from_service_account_json
  source:
    id: from_service_account_json
    path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
    remote:
      branch: main
      path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
      repo: git@github.com:googleapis/python-bigquery-storage.git
    startLine: 137
  summary: "Creates an instance of this client using the provided credentials\n  \
    \  file.\n"
  syntax:
    content: 'from_service_account_json(filename: str, *args, **kwargs)'
    parameters:
    - description: The path to the service account private key json file.
      id: filename
      var_type: str
    returns:
    - description: The constructed client.
      var_type: BigQueryReadClient
  type: method
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.from_service_account_json
- attributes: []
  class: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.get_mtls_endpoint_and_cert_source
  langs:
  - python
  module: google.cloud.bigquery_storage_v1beta2.client
  name: get_mtls_endpoint_and_cert_source
  source:
    id: get_mtls_endpoint_and_cert_source
    path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
    remote:
      branch: main
      path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
      repo: git@github.com:googleapis/python-bigquery-storage.git
    startLine: 276
  summary: 'Return the API endpoint and client cert source for mutual TLS.


    The client cert source is determined in the following order:

    (1) if `GOOGLE_API_USE_CLIENT_CERTIFICATE` environment variable is not "true",
    the

    client cert source is None.

    (2) if `client_options.client_cert_source` is provided, use the provided one;
    if the

    default client cert source exists, use the default one; otherwise the client cert

    source is None.


    The API endpoint is determined in the following order:

    (1) if `client_options.api_endpoint` if provided, use the provided one.

    (2) if `GOOGLE_API_USE_CLIENT_CERTIFICATE` environment variable is "always", use
    the

    default mTLS endpoint; if the environment variabel is "never", use the default
    API

    endpoint; otherwise if client cert source exists, use the default mTLS endpoint,
    otherwise

    use the default API endpoint.


    More details can be found at https://google.aip.dev/auth/4114.

    '
  syntax:
    content: "get_mtls_endpoint_and_cert_source(\n    client_options: typing.Optional[\n\
      \        google.api_core.client_options.ClientOptions\n    ] = None,\n)"
    exceptions:
    - description: If any errors happen.
      var_type: google.auth.exceptions.MutualTLSChannelError
    parameters:
    - defaultValue: None
      description: Custom options for the client. Only the `api_endpoint` and `client_cert_source`
        properties may be used in this method.
      id: client_options
      var_type: google.api_core.client_options.ClientOptions
    returns:
    - description: returns the API endpoint and the client cert source to use.
      var_type: Tuple[str, Callable[[], Tuple[bytes, bytes]]]
  type: method
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.get_mtls_endpoint_and_cert_source
- attributes: []
  class: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.parse_common_billing_account_path
  langs:
  - python
  module: google.cloud.bigquery_storage_v1beta2.client
  name: parse_common_billing_account_path
  source:
    id: parse_common_billing_account_path
    path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
    remote:
      branch: main
      path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
      repo: git@github.com:googleapis/python-bigquery-storage.git
    startLine: 224
  summary: 'Parse a billing_account path into its component segments.


    '
  syntax:
    content: 'parse_common_billing_account_path(path: str)'
    parameters: []
  type: method
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.parse_common_billing_account_path
- attributes: []
  class: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.parse_common_folder_path
  langs:
  - python
  module: google.cloud.bigquery_storage_v1beta2.client
  name: parse_common_folder_path
  source:
    id: parse_common_folder_path
    path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
    remote:
      branch: main
      path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
      repo: git@github.com:googleapis/python-bigquery-storage.git
    startLine: 235
  summary: 'Parse a folder path into its component segments.


    '
  syntax:
    content: 'parse_common_folder_path(path: str)'
    parameters: []
  type: method
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.parse_common_folder_path
- attributes: []
  class: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.parse_common_location_path
  langs:
  - python
  module: google.cloud.bigquery_storage_v1beta2.client
  name: parse_common_location_path
  source:
    id: parse_common_location_path
    path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
    remote:
      branch: main
      path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
      repo: git@github.com:googleapis/python-bigquery-storage.git
    startLine: 270
  summary: 'Parse a location path into its component segments.


    '
  syntax:
    content: 'parse_common_location_path(path: str)'
    parameters: []
  type: method
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.parse_common_location_path
- attributes: []
  class: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.parse_common_organization_path
  langs:
  - python
  module: google.cloud.bigquery_storage_v1beta2.client
  name: parse_common_organization_path
  source:
    id: parse_common_organization_path
    path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
    remote:
      branch: main
      path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
      repo: git@github.com:googleapis/python-bigquery-storage.git
    startLine: 246
  summary: 'Parse a organization path into its component segments.


    '
  syntax:
    content: 'parse_common_organization_path(path: str)'
    parameters: []
  type: method
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.parse_common_organization_path
- attributes: []
  class: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.parse_common_project_path
  langs:
  - python
  module: google.cloud.bigquery_storage_v1beta2.client
  name: parse_common_project_path
  source:
    id: parse_common_project_path
    path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
    remote:
      branch: main
      path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
      repo: git@github.com:googleapis/python-bigquery-storage.git
    startLine: 257
  summary: 'Parse a project path into its component segments.


    '
  syntax:
    content: 'parse_common_project_path(path: str)'
    parameters: []
  type: method
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.parse_common_project_path
- attributes: []
  class: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.parse_read_session_path
  langs:
  - python
  module: google.cloud.bigquery_storage_v1beta2.client
  name: parse_read_session_path
  source:
    id: parse_read_session_path
    path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
    remote:
      branch: main
      path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
      repo: git@github.com:googleapis/python-bigquery-storage.git
    startLine: 174
  summary: 'Parses a read_session path into its component segments.


    '
  syntax:
    content: 'parse_read_session_path(path: str)'
    parameters: []
  type: method
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.parse_read_session_path
- attributes: []
  class: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.parse_read_stream_path
  langs:
  - python
  module: google.cloud.bigquery_storage_v1beta2.client
  name: parse_read_stream_path
  source:
    id: parse_read_stream_path
    path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
    remote:
      branch: main
      path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
      repo: git@github.com:googleapis/python-bigquery-storage.git
    startLine: 192
  summary: 'Parses a read_stream path into its component segments.


    '
  syntax:
    content: 'parse_read_stream_path(path: str)'
    parameters: []
  type: method
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.parse_read_stream_path
- attributes: []
  class: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.parse_table_path
  langs:
  - python
  module: google.cloud.bigquery_storage_v1beta2.client
  name: parse_table_path
  source:
    id: parse_table_path
    path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
    remote:
      branch: main
      path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
      repo: git@github.com:googleapis/python-bigquery-storage.git
    startLine: 208
  summary: 'Parses a table path into its component segments.


    '
  syntax:
    content: 'parse_table_path(path: str)'
    parameters: []
  type: method
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.parse_table_path
- attributes: []
  class: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.read_rows
  langs:
  - python
  module: google.cloud.bigquery_storage_v1beta2.client
  name: read_rows
  source:
    id: read_rows
    path: google/cloud/bigquery_storage_v1beta2/client.py
    remote:
      branch: main
      path: google/cloud/bigquery_storage_v1beta2/client.py
      repo: git@github.com:googleapis/python-bigquery-storage.git
    startLine: 44
  summary: 'Reads rows from the table in the format prescribed by the read

    session. Each response contains one or more table rows, up to a

    maximum of 10 MiB per response; read requests which attempt to read

    individual rows larger than this will fail.


    Each request also returns a set of stream statistics reflecting the

    estimated total number of rows in the read stream. This number is

    computed based on the total table size and the number of active

    streams in the read session, and may change as other streams continue

    to read data.


    .. rubric:: Example


    >>> from google.cloud import bigquery_storage

    >>>

    >>> client = bigquery_storage.BigQueryReadClient()

    >>>

    >>> # TODO: Initialize ``table``:

    >>> table = "projects/{}/datasets/{}/tables/{}".format(

    ...     ''project_id'': ''your-data-project-id'',

    ...     ''dataset_id'': ''your_dataset_id'',

    ...     ''table_id'': ''your_table_id'',

    ... )

    >>>

    >>> # TODO: Initialize `parent`:

    >>> parent = ''projects/your-billing-project-id''

    >>>

    >>> requested_session = bigquery_storage.types.ReadSession(

    ...     table=table,

    ...     data_format=bigquery_storage.types.DataFormat.AVRO,

    ... )

    >>> session = client.create_read_session(

    ...     parent=parent, read_session=requested_session

    ... )

    >>>

    >>> stream = session.streams[0],  # TODO: Also read any other streams.

    >>> read_rows_stream = client.read_rows(stream.name)

    >>>

    >>> for element in read_rows_stream.rows(session):

    ...     # process element

    ...     pass

    '
  syntax:
    content: "read_rows(\n    name,\n    offset=0,\n    retry=_MethodDefault._DEFAULT_VALUE,\n\
      \    timeout=_MethodDefault._DEFAULT_VALUE,\n    metadata=(),\n    retry_delay_callback=None,\n\
      )"
    exceptions:
    - description: If the request failed for any reason.
      var_type: google.api_core.exceptions.GoogleAPICallError
    - description: If the request failed due to a retryable error and retry attempts
        failed.
      var_type: google.api_core.exceptions.RetryError
    - description: If the parameters are invalid.
      var_type: ValueError
    parameters:
    - description: Required. Name of the stream to start reading from, of the form
        `projects/{project_id}/locations/{location}/sessions/{session_id}/streams/{stream_id}`
      id: name
      var_type: str
    - description: The starting offset from which to begin reading rows from in the
        stream. The offset requested must be less than the last row read from ReadRows.
        Requesting a larger offset is undefined.
      id: offset
      var_type: Optional[int]
    - description: A retry object used to retry requests. If ``None`` is specified,
        requests will not be retried.
      id: retry
      var_type: Optional[google.api_core.retry.Retry]
    - description: The amount of time, in seconds, to wait for the request to complete.
        Note that if ``retry`` is specified, the timeout applies to each individual
        attempt.
      id: timeout
      var_type: Optional[float]
    - description: Additional metadata that is provided to the method.
      id: metadata
      var_type: Optional[Sequence[Tuple[str, str]]]
    - description: If the client receives a retryable error that asks the client to
        delay its next attempt and retry_delay_callback is not None, BigQueryReadClient
        will call retry_delay_callback with the delay duration (in seconds) before
        it starts sleeping until the next attempt.
      id: retry_delay_callback
      var_type: Optional[Callable[[float], None]]
    returns:
    - description: An iterable of <xref uid="google.cloud.bigquery_storage_v1.types.ReadRowsResponse">ReadRowsResponse</xref>.
      var_type: <xref uid="google.cloud.bigquery_storage_v1.reader.ReadRowsStream">ReadRowsStream</xref>
  type: method
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.read_rows
- attributes: []
  class: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.read_session_path
  langs:
  - python
  module: google.cloud.bigquery_storage_v1beta2.client
  name: read_session_path
  source:
    id: read_session_path
    path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
    remote:
      branch: main
      path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
      repo: git@github.com:googleapis/python-bigquery-storage.git
    startLine: 167
  summary: 'Returns a fully-qualified read_session string.


    '
  syntax:
    content: 'read_session_path(project: str, location: str, session: str)'
    parameters: []
  type: method
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.read_session_path
- attributes: []
  class: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.read_stream_path
  langs:
  - python
  module: google.cloud.bigquery_storage_v1beta2.client
  name: read_stream_path
  source:
    id: read_stream_path
    path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
    remote:
      branch: main
      path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
      repo: git@github.com:googleapis/python-bigquery-storage.git
    startLine: 183
  summary: 'Returns a fully-qualified read_stream string.


    '
  syntax:
    content: 'read_stream_path(project: str, location: str, session: str, stream:
      str)'
    parameters: []
  type: method
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.read_stream_path
- attributes: []
  class: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.split_read_stream
  langs:
  - python
  module: google.cloud.bigquery_storage_v1beta2.client
  name: split_read_stream
  source:
    id: split_read_stream
    path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
    remote:
      branch: main
      path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
      repo: git@github.com:googleapis/python-bigquery-storage.git
    startLine: 654
  summary: 'Splits a given ``ReadStream`` into two ``ReadStream`` objects.

    These ``ReadStream`` objects are referred to as the primary and

    the residual streams of the split. The original ``ReadStream``

    can still be read from in the same manner as before. Both of the

    returned ``ReadStream`` objects can also be read from, and the

    rows returned by both child streams will be the same as the rows

    read from the original stream.


    Moreover, the two child streams will be allocated back-to-back

    in the original ``ReadStream``. Concretely, it is guaranteed

    that for streams original, primary, and residual, that

    original[0-j] = primary[0-j] and original[j-n] = residual[0-m]

    once the streams have been read to completion.

    '
  syntax:
    content: "split_read_stream(\n    request: typing.Optional[\n        typing.Union[\n\
      \            google.cloud.bigquery_storage_v1beta2.types.storage.SplitReadStreamRequest,\n\
      \            dict,\n        ]\n    ] = None,\n    *,\n    retry: typing.Union[\n\
      \        google.api_core.retry.Retry, google.api_core.gapic_v1.method._MethodDefault\n\
      \    ] = _MethodDefault._DEFAULT_VALUE,\n    timeout: typing.Optional[float]\
      \ = None,\n    metadata: typing.Sequence[typing.Tuple[str, str]] = ()\n)"
    parameters:
    - defaultValue: None
      description: The request object. Request message for `SplitReadStream`.
      id: request
      var_type: Union[<xref uid="google.cloud.bigquery_storage_v1beta2.types.SplitReadStreamRequest">google.cloud.bigquery_storage_v1beta2.types.SplitReadStreamRequest</xref>,
        dict]
    - description: Designation of what errors, if any, should be retried.
      id: retry
      var_type: google.api_core.retry.Retry
    - description: The timeout for this request.
      id: timeout
      var_type: float
    - description: Strings which should be sent along with the request as metadata.
      id: metadata
      var_type: Sequence[Tuple[str, str]]
  type: method
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.split_read_stream
- attributes: []
  class: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.table_path
  langs:
  - python
  module: google.cloud.bigquery_storage_v1beta2.client
  name: table_path
  source:
    id: table_path
    path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
    remote:
      branch: main
      path: google/cloud/bigquery_storage_v1beta2/services/big_query_read/client.py
      repo: git@github.com:googleapis/python-bigquery-storage.git
    startLine: 201
  summary: 'Returns a fully-qualified table string.


    '
  syntax:
    content: 'table_path(project: str, dataset: str, table: str)'
    parameters: []
  type: method
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.table_path
- &id001
  attributes: []
  class: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.transport
  langs:
  - python
  module: google.cloud.bigquery_storage_v1beta2.client
  name: transport
  source:
    id: transport
    path: null
    remote:
      branch: main
      path: null
      repo: git@github.com:googleapis/python-bigquery-storage.git
    startLine: null
  summary: 'Returns the transport used by the client instance.

    '
  syntax:
    returns:
    - description: The transport used by the client instance.
      var_type: BigQueryReadTransport
  type: property
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.transport
- *id001
references:
- fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  isExternal: false
  name: BigQueryReadClient
  parent: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
- fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.__exit__
  isExternal: false
  name: __exit__
  parent: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.__exit__
- fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.common_billing_account_path
  isExternal: false
  name: common_billing_account_path
  parent: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.common_billing_account_path
- fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.common_folder_path
  isExternal: false
  name: common_folder_path
  parent: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.common_folder_path
- fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.common_location_path
  isExternal: false
  name: common_location_path
  parent: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.common_location_path
- fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.common_organization_path
  isExternal: false
  name: common_organization_path
  parent: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.common_organization_path
- fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.common_project_path
  isExternal: false
  name: common_project_path
  parent: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.common_project_path
- fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.create_read_session
  isExternal: false
  name: create_read_session
  parent: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.create_read_session
- fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.from_service_account_file
  isExternal: false
  name: from_service_account_file
  parent: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.from_service_account_file
- fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.from_service_account_info
  isExternal: false
  name: from_service_account_info
  parent: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.from_service_account_info
- fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.from_service_account_json
  isExternal: false
  name: from_service_account_json
  parent: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.from_service_account_json
- fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.get_mtls_endpoint_and_cert_source
  isExternal: false
  name: get_mtls_endpoint_and_cert_source
  parent: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.get_mtls_endpoint_and_cert_source
- fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.parse_common_billing_account_path
  isExternal: false
  name: parse_common_billing_account_path
  parent: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.parse_common_billing_account_path
- fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.parse_common_folder_path
  isExternal: false
  name: parse_common_folder_path
  parent: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.parse_common_folder_path
- fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.parse_common_location_path
  isExternal: false
  name: parse_common_location_path
  parent: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.parse_common_location_path
- fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.parse_common_organization_path
  isExternal: false
  name: parse_common_organization_path
  parent: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.parse_common_organization_path
- fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.parse_common_project_path
  isExternal: false
  name: parse_common_project_path
  parent: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.parse_common_project_path
- fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.parse_read_session_path
  isExternal: false
  name: parse_read_session_path
  parent: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.parse_read_session_path
- fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.parse_read_stream_path
  isExternal: false
  name: parse_read_stream_path
  parent: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.parse_read_stream_path
- fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.parse_table_path
  isExternal: false
  name: parse_table_path
  parent: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.parse_table_path
- fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.read_rows
  isExternal: false
  name: read_rows
  parent: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.read_rows
- fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.read_session_path
  isExternal: false
  name: read_session_path
  parent: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.read_session_path
- fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.read_stream_path
  isExternal: false
  name: read_stream_path
  parent: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.read_stream_path
- fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.split_read_stream
  isExternal: false
  name: split_read_stream
  parent: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.split_read_stream
- fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.table_path
  isExternal: false
  name: table_path
  parent: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.table_path
- fullName: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.transport
  isExternal: false
  name: transport
  parent: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient
  uid: google.cloud.bigquery_storage_v1beta2.client.BigQueryReadClient.transport
