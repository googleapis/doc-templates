<!DOCTYPE html>
<html devsite="">
  <head>
    <meta name="project_path" value="/java/_project.yaml">
    <meta name="book_path" value="/java/_book.yaml">
  </head>
  <body>
    {% verbatim %}
    <div>
      <article data-uid="com.google.cloud.speech.v1.StreamingRecognizeRequestOrBuilder">
<h1 class="page-title">Interface StreamingRecognizeRequestOrBuilder (2.0.0)</h1>
  
  
  <div class="codewrapper">
    <pre class="prettyprint"><code>public interface StreamingRecognizeRequestOrBuilder extends MessageOrBuilder</code></pre>
  </div>
  <div classs="implements">
    <h2>Implements</h2>
    <span><a class="xref" href="https://cloud.google.com/java/docs/reference/protobuf/latest/com.google.protobuf.MessageOrBuilder.html">MessageOrBuilder</a></span>
  </div>
  <h2 id="methods">Methods
  </h2>
  <a id="com_google_cloud_speech_v1_StreamingRecognizeRequestOrBuilder_getAudioContent_" data-uid="com.google.cloud.speech.v1.StreamingRecognizeRequestOrBuilder.getAudioContent*"></a>
  <h3 id="com_google_cloud_speech_v1_StreamingRecognizeRequestOrBuilder_getAudioContent__" data-uid="com.google.cloud.speech.v1.StreamingRecognizeRequestOrBuilder.getAudioContent()" class="notranslate">getAudioContent()</h3>
  <div class="codewrapper">
    <pre class="prettyprint"><code>public abstract ByteString getAudioContent()</code></pre>
  </div>
  <div class="markdown level1 summary"><p> The audio data to be recognized. Sequential chunks of audio data are sent
 in sequential <code>StreamingRecognizeRequest</code> messages. The first
 <code>StreamingRecognizeRequest</code> message must not contain <code>audio_content</code> data
 and all subsequent <code>StreamingRecognizeRequest</code> messages must contain
 <code>audio_content</code> data. The audio bytes must be encoded as specified in
 <code>RecognitionConfig</code>. Note: as with all bytes fields, proto buffers use a
 pure binary representation (not base64). See
 <a href="https://cloud.google.com/speech-to-text/quotas#content">content limits</a>.</p>
<p> <code>bytes audio_content = 2;</code></p>
</div>
  <strong>Returns</strong>
  <table class="responsive">
    <tbody>
      <tr>
        <td><strong>Type</strong></td>
        <td><strong>Description</strong></td>
      </tr>
      <tr>
        <td><a class="xref" href="https://cloud.google.com/java/docs/reference/protobuf/latest/com.google.protobuf.ByteString.html">ByteString</a></td>
        <td><p>The audioContent.</p>
</td>
      </tr>
    </tbody>
  </table>
  <a id="com_google_cloud_speech_v1_StreamingRecognizeRequestOrBuilder_getStreamingConfig_" data-uid="com.google.cloud.speech.v1.StreamingRecognizeRequestOrBuilder.getStreamingConfig*"></a>
  <h3 id="com_google_cloud_speech_v1_StreamingRecognizeRequestOrBuilder_getStreamingConfig__" data-uid="com.google.cloud.speech.v1.StreamingRecognizeRequestOrBuilder.getStreamingConfig()" class="notranslate">getStreamingConfig()</h3>
  <div class="codewrapper">
    <pre class="prettyprint"><code>public abstract StreamingRecognitionConfig getStreamingConfig()</code></pre>
  </div>
  <div class="markdown level1 summary"><p> Provides information to the recognizer that specifies how to process the
 request. The first <code>StreamingRecognizeRequest</code> message must contain a
 <code>streaming_config</code>  message.</p>
<p> <code>.google.cloud.speech.v1.StreamingRecognitionConfig streaming_config = 1;</code></p>
</div>
  <strong>Returns</strong>
  <table class="responsive">
    <tbody>
      <tr>
        <td><strong>Type</strong></td>
        <td><strong>Description</strong></td>
      </tr>
      <tr>
        <td><a class="xref" href="com.google.cloud.speech.v1.StreamingRecognitionConfig.html">StreamingRecognitionConfig</a></td>
        <td><p>The streamingConfig.</p>
</td>
      </tr>
    </tbody>
  </table>
  <a id="com_google_cloud_speech_v1_StreamingRecognizeRequestOrBuilder_getStreamingConfigOrBuilder_" data-uid="com.google.cloud.speech.v1.StreamingRecognizeRequestOrBuilder.getStreamingConfigOrBuilder*"></a>
  <h3 id="com_google_cloud_speech_v1_StreamingRecognizeRequestOrBuilder_getStreamingConfigOrBuilder__" data-uid="com.google.cloud.speech.v1.StreamingRecognizeRequestOrBuilder.getStreamingConfigOrBuilder()" class="notranslate">getStreamingConfigOrBuilder()</h3>
  <div class="codewrapper">
    <pre class="prettyprint"><code>public abstract StreamingRecognitionConfigOrBuilder getStreamingConfigOrBuilder()</code></pre>
  </div>
  <div class="markdown level1 summary"><p> Provides information to the recognizer that specifies how to process the
 request. The first <code>StreamingRecognizeRequest</code> message must contain a
 <code>streaming_config</code>  message.</p>
<p> <code>.google.cloud.speech.v1.StreamingRecognitionConfig streaming_config = 1;</code></p>
</div>
  <strong>Returns</strong>
  <table class="responsive">
    <tbody>
      <tr>
        <td><strong>Type</strong></td>
        <td><strong>Description</strong></td>
      </tr>
      <tr>
        <td><a class="xref" href="com.google.cloud.speech.v1.StreamingRecognitionConfigOrBuilder.html">StreamingRecognitionConfigOrBuilder</a></td>
        <td></td>
      </tr>
    </tbody>
  </table>
  <a id="com_google_cloud_speech_v1_StreamingRecognizeRequestOrBuilder_getStreamingRequestCase_" data-uid="com.google.cloud.speech.v1.StreamingRecognizeRequestOrBuilder.getStreamingRequestCase*"></a>
  <h3 id="com_google_cloud_speech_v1_StreamingRecognizeRequestOrBuilder_getStreamingRequestCase__" data-uid="com.google.cloud.speech.v1.StreamingRecognizeRequestOrBuilder.getStreamingRequestCase()" class="notranslate">getStreamingRequestCase()</h3>
  <div class="codewrapper">
    <pre class="prettyprint"><code>public abstract StreamingRecognizeRequest.StreamingRequestCase getStreamingRequestCase()</code></pre>
  </div>
  <strong>Returns</strong>
  <table class="responsive">
    <tbody>
      <tr>
        <td><strong>Type</strong></td>
        <td><strong>Description</strong></td>
      </tr>
      <tr>
        <td><a class="xref" href="com.google.cloud.speech.v1.StreamingRecognizeRequest.StreamingRequestCase.html">StreamingRecognizeRequest.StreamingRequestCase</a></td>
        <td></td>
      </tr>
    </tbody>
  </table>
  <a id="com_google_cloud_speech_v1_StreamingRecognizeRequestOrBuilder_hasAudioContent_" data-uid="com.google.cloud.speech.v1.StreamingRecognizeRequestOrBuilder.hasAudioContent*"></a>
  <h3 id="com_google_cloud_speech_v1_StreamingRecognizeRequestOrBuilder_hasAudioContent__" data-uid="com.google.cloud.speech.v1.StreamingRecognizeRequestOrBuilder.hasAudioContent()" class="notranslate">hasAudioContent()</h3>
  <div class="codewrapper">
    <pre class="prettyprint"><code>public abstract boolean hasAudioContent()</code></pre>
  </div>
  <div class="markdown level1 summary"><p> The audio data to be recognized. Sequential chunks of audio data are sent
 in sequential <code>StreamingRecognizeRequest</code> messages. The first
 <code>StreamingRecognizeRequest</code> message must not contain <code>audio_content</code> data
 and all subsequent <code>StreamingRecognizeRequest</code> messages must contain
 <code>audio_content</code> data. The audio bytes must be encoded as specified in
 <code>RecognitionConfig</code>. Note: as with all bytes fields, proto buffers use a
 pure binary representation (not base64). See
 <a href="https://cloud.google.com/speech-to-text/quotas#content">content limits</a>.</p>
<p> <code>bytes audio_content = 2;</code></p>
</div>
  <strong>Returns</strong>
  <table class="responsive">
    <tbody>
      <tr>
        <td><strong>Type</strong></td>
        <td><strong>Description</strong></td>
      </tr>
      <tr>
        <td><a class="xref" href="https://docs.oracle.com/javase/tutorial/java/nutsandbolts/datatypes.html">boolean</a></td>
        <td><p>Whether the audioContent field is set.</p>
</td>
      </tr>
    </tbody>
  </table>
  <a id="com_google_cloud_speech_v1_StreamingRecognizeRequestOrBuilder_hasStreamingConfig_" data-uid="com.google.cloud.speech.v1.StreamingRecognizeRequestOrBuilder.hasStreamingConfig*"></a>
  <h3 id="com_google_cloud_speech_v1_StreamingRecognizeRequestOrBuilder_hasStreamingConfig__" data-uid="com.google.cloud.speech.v1.StreamingRecognizeRequestOrBuilder.hasStreamingConfig()" class="notranslate">hasStreamingConfig()</h3>
  <div class="codewrapper">
    <pre class="prettyprint"><code>public abstract boolean hasStreamingConfig()</code></pre>
  </div>
  <div class="markdown level1 summary"><p> Provides information to the recognizer that specifies how to process the
 request. The first <code>StreamingRecognizeRequest</code> message must contain a
 <code>streaming_config</code>  message.</p>
<p> <code>.google.cloud.speech.v1.StreamingRecognitionConfig streaming_config = 1;</code></p>
</div>
  <strong>Returns</strong>
  <table class="responsive">
    <tbody>
      <tr>
        <td><strong>Type</strong></td>
        <td><strong>Description</strong></td>
      </tr>
      <tr>
        <td><a class="xref" href="https://docs.oracle.com/javase/tutorial/java/nutsandbolts/datatypes.html">boolean</a></td>
        <td><p>Whether the streamingConfig field is set.</p>
</td>
      </tr>
    </tbody>
  </table>
</article>
    </div>
    {% endverbatim %}
  </body>
</html>
