<!DOCTYPE html>
<html devsite="">
  <head>
    <meta name="project_path" value="/java/_project.yaml">
    <meta name="book_path" value="/java/_book.yaml">
  </head>
  <body>
    {% verbatim %}
    <div>
      <article data-uid="com.google.cloud.speech.v1.StreamingRecognizeRequestOrBuilder">
<h1 class="page-title">Interface StreamingRecognizeRequestOrBuilder
</h1>
  
  
  <div class="codewrapper">
    <pre class="prettyprint"><code>public interface StreamingRecognizeRequestOrBuilder extends MessageOrBuilder</code></pre>
  </div>
  <div classs="implements">
    <h2>Implements</h2>
    <span><a class="xref" href="https://cloud.google.com/java/docs/reference/protobuf/latest/com.google.protobuf.MessageOrBuilder.html">MessageOrBuilder</a></span>
  </div>
  <h2 id="methods">Methods
  </h2>
  <a id="com_google_cloud_speech_v1_StreamingRecognizeRequestOrBuilder_getAudioContent_" data-uid="com.google.cloud.speech.v1.StreamingRecognizeRequestOrBuilder.getAudioContent*"></a>
  <h3 id="com_google_cloud_speech_v1_StreamingRecognizeRequestOrBuilder_getAudioContent__" data-uid="com.google.cloud.speech.v1.StreamingRecognizeRequestOrBuilder.getAudioContent()" class="notranslate">getAudioContent()</h3>
  <div class="codewrapper">
    <pre class="prettyprint"><code>public abstract ByteString getAudioContent()</code></pre>
  </div>
  <div class="markdown level1 summary"><pre><code>The audio data to be recognized. Sequential chunks of audio data are sent
 in sequential `StreamingRecognizeRequest` messages. The first
 `StreamingRecognizeRequest` message must not contain `audio_content` data
 and all subsequent `StreamingRecognizeRequest` messages must contain
 `audio_content` data. The audio bytes must be encoded as specified in
 `RecognitionConfig`. Note: as with all bytes fields, proto buffers use a
 pure binary representation (not base64). See
 [content limits](https://cloud.google.com/speech-to-text/quotas#content).
</code></pre><p><code>bytes audio_content = 2;</code></p>
</div>
  <strong>Returns</strong>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="https://cloud.google.com/java/docs/reference/protobuf/latest/com.google.protobuf.ByteString.html">ByteString</a></td>
        <td><p>The audioContent.</p>
</td>
      </tr>
    </tbody>
  </table>
  <a id="com_google_cloud_speech_v1_StreamingRecognizeRequestOrBuilder_getStreamingConfig_" data-uid="com.google.cloud.speech.v1.StreamingRecognizeRequestOrBuilder.getStreamingConfig*"></a>
  <h3 id="com_google_cloud_speech_v1_StreamingRecognizeRequestOrBuilder_getStreamingConfig__" data-uid="com.google.cloud.speech.v1.StreamingRecognizeRequestOrBuilder.getStreamingConfig()" class="notranslate">getStreamingConfig()</h3>
  <div class="codewrapper">
    <pre class="prettyprint"><code>public abstract StreamingRecognitionConfig getStreamingConfig()</code></pre>
  </div>
  <div class="markdown level1 summary"><pre><code>Provides information to the recognizer that specifies how to process the
 request. The first `StreamingRecognizeRequest` message must contain a
 `streaming_config`  message.
</code></pre><p><code>.google.cloud.speech.v1.StreamingRecognitionConfig streaming_config = 1;</code></p>
</div>
  <strong>Returns</strong>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="com.google.cloud.speech.v1.StreamingRecognitionConfig.html">StreamingRecognitionConfig</a></td>
        <td><p>The streamingConfig.</p>
</td>
      </tr>
    </tbody>
  </table>
  <a id="com_google_cloud_speech_v1_StreamingRecognizeRequestOrBuilder_getStreamingConfigOrBuilder_" data-uid="com.google.cloud.speech.v1.StreamingRecognizeRequestOrBuilder.getStreamingConfigOrBuilder*"></a>
  <h3 id="com_google_cloud_speech_v1_StreamingRecognizeRequestOrBuilder_getStreamingConfigOrBuilder__" data-uid="com.google.cloud.speech.v1.StreamingRecognizeRequestOrBuilder.getStreamingConfigOrBuilder()" class="notranslate">getStreamingConfigOrBuilder()</h3>
  <div class="codewrapper">
    <pre class="prettyprint"><code>public abstract StreamingRecognitionConfigOrBuilder getStreamingConfigOrBuilder()</code></pre>
  </div>
  <div class="markdown level1 summary"><pre><code>Provides information to the recognizer that specifies how to process the
 request. The first `StreamingRecognizeRequest` message must contain a
 `streaming_config`  message.
</code></pre><p><code>.google.cloud.speech.v1.StreamingRecognitionConfig streaming_config = 1;</code></p>
</div>
  <strong>Returns</strong>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="com.google.cloud.speech.v1.StreamingRecognitionConfigOrBuilder.html">StreamingRecognitionConfigOrBuilder</a></td>
        <td></td>
      </tr>
    </tbody>
  </table>
  <a id="com_google_cloud_speech_v1_StreamingRecognizeRequestOrBuilder_getStreamingRequestCase_" data-uid="com.google.cloud.speech.v1.StreamingRecognizeRequestOrBuilder.getStreamingRequestCase*"></a>
  <h3 id="com_google_cloud_speech_v1_StreamingRecognizeRequestOrBuilder_getStreamingRequestCase__" data-uid="com.google.cloud.speech.v1.StreamingRecognizeRequestOrBuilder.getStreamingRequestCase()" class="notranslate">getStreamingRequestCase()</h3>
  <div class="codewrapper">
    <pre class="prettyprint"><code>public abstract StreamingRecognizeRequest.StreamingRequestCase getStreamingRequestCase()</code></pre>
  </div>
  <strong>Returns</strong>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="com.google.cloud.speech.v1.StreamingRecognizeRequest.StreamingRequestCase.html">StreamingRecognizeRequest.StreamingRequestCase</a></td>
        <td></td>
      </tr>
    </tbody>
  </table>
  <a id="com_google_cloud_speech_v1_StreamingRecognizeRequestOrBuilder_hasAudioContent_" data-uid="com.google.cloud.speech.v1.StreamingRecognizeRequestOrBuilder.hasAudioContent*"></a>
  <h3 id="com_google_cloud_speech_v1_StreamingRecognizeRequestOrBuilder_hasAudioContent__" data-uid="com.google.cloud.speech.v1.StreamingRecognizeRequestOrBuilder.hasAudioContent()" class="notranslate">hasAudioContent()</h3>
  <div class="codewrapper">
    <pre class="prettyprint"><code>public abstract boolean hasAudioContent()</code></pre>
  </div>
  <div class="markdown level1 summary"><pre><code>The audio data to be recognized. Sequential chunks of audio data are sent
 in sequential `StreamingRecognizeRequest` messages. The first
 `StreamingRecognizeRequest` message must not contain `audio_content` data
 and all subsequent `StreamingRecognizeRequest` messages must contain
 `audio_content` data. The audio bytes must be encoded as specified in
 `RecognitionConfig`. Note: as with all bytes fields, proto buffers use a
 pure binary representation (not base64). See
 [content limits](https://cloud.google.com/speech-to-text/quotas#content).
</code></pre><p><code>bytes audio_content = 2;</code></p>
</div>
  <strong>Returns</strong>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="https://docs.oracle.com/javase/tutorial/java/nutsandbolts/datatypes.html">boolean</a></td>
        <td><p>Whether the audioContent field is set.</p>
</td>
      </tr>
    </tbody>
  </table>
  <a id="com_google_cloud_speech_v1_StreamingRecognizeRequestOrBuilder_hasStreamingConfig_" data-uid="com.google.cloud.speech.v1.StreamingRecognizeRequestOrBuilder.hasStreamingConfig*"></a>
  <h3 id="com_google_cloud_speech_v1_StreamingRecognizeRequestOrBuilder_hasStreamingConfig__" data-uid="com.google.cloud.speech.v1.StreamingRecognizeRequestOrBuilder.hasStreamingConfig()" class="notranslate">hasStreamingConfig()</h3>
  <div class="codewrapper">
    <pre class="prettyprint"><code>public abstract boolean hasStreamingConfig()</code></pre>
  </div>
  <div class="markdown level1 summary"><pre><code>Provides information to the recognizer that specifies how to process the
 request. The first `StreamingRecognizeRequest` message must contain a
 `streaming_config`  message.
</code></pre><p><code>.google.cloud.speech.v1.StreamingRecognitionConfig streaming_config = 1;</code></p>
</div>
  <strong>Returns</strong>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="https://docs.oracle.com/javase/tutorial/java/nutsandbolts/datatypes.html">boolean</a></td>
        <td><p>Whether the streamingConfig field is set.</p>
</td>
      </tr>
    </tbody>
  </table>
</article>
    </div>
    {% endverbatim %}
  </body>
</html>
