<!DOCTYPE html>
<html devsite="">
  <head>
    <meta name="project_path" value="/java/_project.yaml">
    <meta name="book_path" value="/java/_book.yaml">
  </head>
  <body>
    <div>
      <article data-uid="com.google.cloud.speech.v1beta1.RecognitionConfig.AudioEncoding">
<h1 class="page-title">Enum RecognitionConfig.AudioEncoding
</h1>
  
  
  <div class="markdown level0 summary"><pre><code>Audio encoding of the data sent in the audio message. All encodings support
 only 1 channel (mono) audio. Only `FLAC` includes a header that describes
 the bytes of audio that follow the header. The other encodings are raw
 audio bytes with no header.
 For best results, the audio source should be captured and transmitted using
 a lossless encoding (`FLAC` or `LINEAR16`). Recognition accuracy may be
 reduced if lossy codecs (such as AMR, AMR_WB and MULAW) are used to capture
 or transmit the audio, particularly if background noise is present.
</code></pre><p>Protobuf enum <code>google.cloud.speech.v1beta1.RecognitionConfig.AudioEncoding</code></p>
</div>
  <div class="markdown level0 conceptual"></div>
  <div classs="implements">
    <h5>Implements</h5>
    <span><span class="xref">com.google.protobuf.ProtocolMessageEnum</span></span>
  </div>
  <devsite-expandable>
    <div class="inheritedMembers">
      <h5 class="showalways">Inherited Members</h5>
      <div>
        <span class="xref">java.lang.Enum.&lt;T&gt;valueOf(java.lang.Class&lt;T&gt;,java.lang.String)</span>
      </div>
      <div>
        <span class="xref">java.lang.Enum.clone()</span>
      </div>
      <div>
        <span class="xref">java.lang.Enum.compareTo(E)</span>
      </div>
      <div>
        <span class="xref">java.lang.Enum.equals(java.lang.Object)</span>
      </div>
      <div>
        <span class="xref">java.lang.Enum.finalize()</span>
      </div>
      <div>
        <span class="xref">java.lang.Enum.getDeclaringClass()</span>
      </div>
      <div>
        <span class="xref">java.lang.Enum.hashCode()</span>
      </div>
      <div>
        <span class="xref">java.lang.Enum.name()</span>
      </div>
      <div>
        <span class="xref">java.lang.Enum.ordinal()</span>
      </div>
      <div>
        <span class="xref">java.lang.Enum.toString()</span>
      </div>
      <div>
        <span class="xref">java.lang.Object.getClass()</span>
      </div>
      <div>
        <span class="xref">java.lang.Object.notify()</span>
      </div>
      <div>
        <span class="xref">java.lang.Object.notifyAll()</span>
      </div>
      <div>
        <span class="xref">java.lang.Object.wait()</span>
      </div>
      <div>
        <span class="xref">java.lang.Object.wait(long)</span>
      </div>
      <div>
        <span class="xref">java.lang.Object.wait(long,int)</span>
      </div>
    </div>
  </devsite-expandable>
  <h5 id="com_google_cloud_speech_v1beta1_RecognitionConfig_AudioEncoding_syntax">Syntax</h5>
  <div class="codewrapper">
    <pre><code class="prettyprint">public enum RecognitionConfig.AudioEncoding extends Enum&lt;RecognitionConfig.AudioEncoding&gt; implements ProtocolMessageEnum</code></pre>
  </div>
  <h3 id="fields">Fields
  </h3>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Name</th>
        <th>Description</th>
      </tr>
    <thead>
    <tbody>
      <tr>
        <td id="com_google_cloud_speech_v1beta1_RecognitionConfig_AudioEncoding_AMR">AMR</td>
        <td><pre><code>Adaptive Multi-Rate Narrowband codec. `sample_rate` must be 8000 Hz.
</code></pre><p><code>AMR = 4;</code></p>
</td>
      </tr>
      <tr>
        <td id="com_google_cloud_speech_v1beta1_RecognitionConfig_AudioEncoding_AMR_VALUE">AMR_VALUE</td>
        <td><pre><code>Adaptive Multi-Rate Narrowband codec. `sample_rate` must be 8000 Hz.
</code></pre><p><code>AMR = 4;</code></p>
</td>
      </tr>
      <tr>
        <td id="com_google_cloud_speech_v1beta1_RecognitionConfig_AudioEncoding_AMR_WB">AMR_WB</td>
        <td><pre><code>Adaptive Multi-Rate Wideband codec. `sample_rate` must be 16000 Hz.
</code></pre><p><code>AMR_WB = 5;</code></p>
</td>
      </tr>
      <tr>
        <td id="com_google_cloud_speech_v1beta1_RecognitionConfig_AudioEncoding_AMR_WB_VALUE">AMR_WB_VALUE</td>
        <td><pre><code>Adaptive Multi-Rate Wideband codec. `sample_rate` must be 16000 Hz.
</code></pre><p><code>AMR_WB = 5;</code></p>
</td>
      </tr>
      <tr>
        <td id="com_google_cloud_speech_v1beta1_RecognitionConfig_AudioEncoding_ENCODING_UNSPECIFIED">ENCODING_UNSPECIFIED</td>
        <td><pre><code>Not specified. Will return result [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT].
</code></pre><p><code>ENCODING_UNSPECIFIED = 0;</code></p>
</td>
      </tr>
      <tr>
        <td id="com_google_cloud_speech_v1beta1_RecognitionConfig_AudioEncoding_ENCODING_UNSPECIFIED_VALUE">ENCODING_UNSPECIFIED_VALUE</td>
        <td><pre><code>Not specified. Will return result [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT].
</code></pre><p><code>ENCODING_UNSPECIFIED = 0;</code></p>
</td>
      </tr>
      <tr>
        <td id="com_google_cloud_speech_v1beta1_RecognitionConfig_AudioEncoding_FLAC">FLAC</td>
        <td><pre><code>This is the recommended encoding for `SyncRecognize` and
 `StreamingRecognize` because it uses lossless compression; therefore
 recognition accuracy is not compromised by a lossy codec.
 The stream FLAC (Free Lossless Audio Codec) encoding is specified at:
 http://flac.sourceforge.net/documentation.html.
 16-bit and 24-bit samples are supported.
 Not all fields in STREAMINFO are supported.
</code></pre><p><code>FLAC = 2;</code></p>
</td>
      </tr>
      <tr>
        <td id="com_google_cloud_speech_v1beta1_RecognitionConfig_AudioEncoding_FLAC_VALUE">FLAC_VALUE</td>
        <td><pre><code>This is the recommended encoding for `SyncRecognize` and
 `StreamingRecognize` because it uses lossless compression; therefore
 recognition accuracy is not compromised by a lossy codec.
 The stream FLAC (Free Lossless Audio Codec) encoding is specified at:
 http://flac.sourceforge.net/documentation.html.
 16-bit and 24-bit samples are supported.
 Not all fields in STREAMINFO are supported.
</code></pre><p><code>FLAC = 2;</code></p>
</td>
      </tr>
      <tr>
        <td id="com_google_cloud_speech_v1beta1_RecognitionConfig_AudioEncoding_LINEAR16">LINEAR16</td>
        <td><pre><code>Uncompressed 16-bit signed little-endian samples (Linear PCM).
 This is the only encoding that may be used by `AsyncRecognize`.
</code></pre><p><code>LINEAR16 = 1;</code></p>
</td>
      </tr>
      <tr>
        <td id="com_google_cloud_speech_v1beta1_RecognitionConfig_AudioEncoding_LINEAR16_VALUE">LINEAR16_VALUE</td>
        <td><pre><code>Uncompressed 16-bit signed little-endian samples (Linear PCM).
 This is the only encoding that may be used by `AsyncRecognize`.
</code></pre><p><code>LINEAR16 = 1;</code></p>
</td>
      </tr>
      <tr>
        <td id="com_google_cloud_speech_v1beta1_RecognitionConfig_AudioEncoding_MULAW">MULAW</td>
        <td><pre><code>8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
</code></pre><p><code>MULAW = 3;</code></p>
</td>
      </tr>
      <tr>
        <td id="com_google_cloud_speech_v1beta1_RecognitionConfig_AudioEncoding_MULAW_VALUE">MULAW_VALUE</td>
        <td><pre><code>8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
</code></pre><p><code>MULAW = 3;</code></p>
</td>
      </tr>
      <tr>
        <td id="com_google_cloud_speech_v1beta1_RecognitionConfig_AudioEncoding_UNRECOGNIZED">UNRECOGNIZED</td>
        <td></td>
      </tr>
    </tbody>
  </thead></thead></table>
  <h3 id="methods">Methods
  </h3>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Name</th>
        <th>Description</th>
      </tr>
    <thead>
    <tbody>
      <tr>
        <td id="com_google_cloud_speech_v1beta1_RecognitionConfig_AudioEncoding_forNumber_int_">forNumber(int value)</td>
        <td></td>
      </tr>
      <tr>
        <td id="com_google_cloud_speech_v1beta1_RecognitionConfig_AudioEncoding_getDescriptor__">getDescriptor()</td>
        <td></td>
      </tr>
      <tr>
        <td id="com_google_cloud_speech_v1beta1_RecognitionConfig_AudioEncoding_getDescriptorForType__">getDescriptorForType()</td>
        <td></td>
      </tr>
      <tr>
        <td id="com_google_cloud_speech_v1beta1_RecognitionConfig_AudioEncoding_getNumber__">getNumber()</td>
        <td></td>
      </tr>
      <tr>
        <td id="com_google_cloud_speech_v1beta1_RecognitionConfig_AudioEncoding_getValueDescriptor__">getValueDescriptor()</td>
        <td></td>
      </tr>
      <tr>
        <td id="com_google_cloud_speech_v1beta1_RecognitionConfig_AudioEncoding_internalGetValueMap__">internalGetValueMap()</td>
        <td></td>
      </tr>
      <tr>
        <td id="com_google_cloud_speech_v1beta1_RecognitionConfig_AudioEncoding_valueOf_com_google_protobuf_Descriptors_EnumValueDescriptor_">valueOf(Descriptors.EnumValueDescriptor desc)</td>
        <td></td>
      </tr>
      <tr>
        <td id="com_google_cloud_speech_v1beta1_RecognitionConfig_AudioEncoding_valueOf_int_">valueOf(int value)</td>
        <td></td>
      </tr>
      <tr>
        <td id="com_google_cloud_speech_v1beta1_RecognitionConfig_AudioEncoding_valueOf_java_lang_String_">valueOf(String name)</td>
        <td></td>
      </tr>
      <tr>
        <td id="com_google_cloud_speech_v1beta1_RecognitionConfig_AudioEncoding_values__">values()</td>
        <td></td>
      </tr>
    </tbody>
  </thead></thead></table>
</article>
    </div>
  </body>
</html>
