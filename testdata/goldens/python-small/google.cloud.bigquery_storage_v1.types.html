<!DOCTYPE html>
<html devsite="">
  <head>
    <meta name="project_path" value="/python/_project.yaml">
    <meta name="book_path" value="/python/_book.yaml">
  </head>
  <body>
    {% verbatim %}
    <div>
      <article data-uid="google.cloud.bigquery_storage_v1.types">
<h1 class="page-title">Package bigquery_storage_v1.types
</h1>
  
  <div class="markdown level0 summary"><p>API documentation for <code>bigquery_storage_v1.types</code> package.</p>
</div>
  <div class="markdown level0 conceptual"></div>
  <div class="markdown level0 remarks"></div>
    <h2 id="classes">Classes
  
  </h2>
        <h2><a class="xref" href="google.cloud.bigquery_storage_v1.types.ArrowRecordBatch.html">ArrowRecordBatch</a></h2>
        <section><p>Arrow RecordBatch.</p>
<p>Attributes:
    serialized_record_batch (bytes):
        IPC-serialized Arrow RecordBatch.
    row_count (int):
        The count of rows in <code>serialized_record_batch</code>.</p>
</section>
        <h2><a class="xref" href="google.cloud.bigquery_storage_v1.types.ArrowSchema.html">ArrowSchema</a></h2>
        <section><p>Arrow schema as specified in
<a href="https://arrow.apache.org/docs/python/api/datatypes.html">https://arrow.apache.org/docs/python/api/datatypes.html</a> and
serialized to bytes using IPC:
<a href="https://arrow.apache.org/docs/format/Columnar.html#serialization-">https://arrow.apache.org/docs/format/Columnar.html#serialization-</a>
and-interprocess-communication-ipc
See code samples on how this message can be deserialized.</p>
<p>Attributes:
    serialized_schema (bytes):
        IPC serialized Arrow schema.</p>
</section>
        <h2><a class="xref" href="google.cloud.bigquery_storage_v1.types.ArrowSerializationOptions.html">ArrowSerializationOptions</a></h2>
        <section><p>Contains options specific to Arrow Serialization.</p>
<p>Attributes:
    buffer_compression (google.cloud.bigquery_storage_v1.types.ArrowSerializationOptions.CompressionCodec):
        The compression codec to use for Arrow
        buffers in serialized record batches.</p>
</section>
        <h2><a class="xref" href="google.cloud.bigquery_storage_v1.types.AvroRows.html">AvroRows</a></h2>
        <section><p>Avro rows.
Attributes:
    serialized_binary_rows (bytes):
        Binary serialized rows in a block.
    row_count (int):
        The count of rows in the returning block.</p>
</section>
        <h2><a class="xref" href="google.cloud.bigquery_storage_v1.types.AvroSchema.html">AvroSchema</a></h2>
        <section><p>Avro schema.
Attributes:
    schema (str):
        Json serialized schema, as described at
        <a href="https://avro.apache.org/docs/1.8.1/spec.html">https://avro.apache.org/docs/1.8.1/spec.html</a>.</p>
</section>
        <h2><a class="xref" href="google.cloud.bigquery_storage_v1.types.CreateReadSessionRequest.html">CreateReadSessionRequest</a></h2>
        <section><p>Request message for <code>CreateReadSession</code>.
Attributes:
    parent (str):
        Required. The request project that owns the session, in the
        form of <code>projects/{project_id}</code>.
    read_session (google.cloud.bigquery_storage_v1.types.ReadSession):
        Required. Session to be created.
    max_stream_count (int):
        Max initial number of streams. If unset or
        zero, the server will provide a value of streams
        so as to produce reasonable throughput. Must be
        non-negative. The number of streams may be lower
        than the requested number, depending on the
        amount parallelism that is reasonable for the
        table. Error will be returned if the max count
        is greater than the current system max limit of
        1,000.</p>
<pre><code>    Streams must be read starting from offset 0.
</code></pre></section>
        <h2><a class="xref" href="google.cloud.bigquery_storage_v1.types.DataFormat.html">DataFormat</a></h2>
        <section><p>Data format for input or output data.</p>
</section>
        <h2><a class="xref" href="google.cloud.bigquery_storage_v1.types.ReadRowsRequest.html">ReadRowsRequest</a></h2>
        <section><p>Request message for <code>ReadRows</code>.
Attributes:
    read_stream (str):
        Required. Stream to read rows from.
    offset (int):
        The offset requested must be less than the
        last row read from Read. Requesting a larger
        offset is undefined. If not specified, start
        reading from offset zero.</p>
</section>
        <h2><a class="xref" href="google.cloud.bigquery_storage_v1.types.ReadRowsResponse.html">ReadRowsResponse</a></h2>
        <section><p>Response from calling <code>ReadRows</code> may include row data, progress
and throttling information.</p>
<p>Attributes:
    avro_rows (google.cloud.bigquery_storage_v1.types.AvroRows):
        Serialized row data in AVRO format.
    arrow_record_batch (google.cloud.bigquery_storage_v1.types.ArrowRecordBatch):
        Serialized row data in Arrow RecordBatch
        format.
    row_count (int):
        Number of serialized rows in the rows block.
    stats (google.cloud.bigquery_storage_v1.types.StreamStats):
        Statistics for the stream.
    throttle_state (google.cloud.bigquery_storage_v1.types.ThrottleState):
        Throttling state. If unset, the latest
        response still describes the current throttling
        status.
    avro_schema (google.cloud.bigquery_storage_v1.types.AvroSchema):
        Output only. Avro schema.
    arrow_schema (google.cloud.bigquery_storage_v1.types.ArrowSchema):
        Output only. Arrow schema.</p>
</section>
        <h2><a class="xref" href="google.cloud.bigquery_storage_v1.types.ReadSession.html">ReadSession</a></h2>
        <section><p>Information about the ReadSession.
Attributes:
    name (str):
        Output only. Unique identifier for the session, in the form
        <code>projects/{project_id}/locations/{location}/sessions/{session_id}</code>.
    expire_time (google.protobuf.timestamp_pb2.Timestamp):
        Output only. Time at which the session becomes invalid.
        After this time, subsequent requests to read this Session
        will return errors. The expire_time is automatically
        assigned and currently cannot be specified or updated.
    data_format (google.cloud.bigquery_storage_v1.types.DataFormat):
        Immutable. Data format of the output data.
    avro_schema (google.cloud.bigquery_storage_v1.types.AvroSchema):
        Output only. Avro schema.
    arrow_schema (google.cloud.bigquery_storage_v1.types.ArrowSchema):
        Output only. Arrow schema.
    table (str):
        Immutable. Table that this ReadSession is reading from, in
        the form
        <code>projects/{project_id}/datasets/{dataset_id}/tables/{table_id}</code>
    table_modifiers (google.cloud.bigquery_storage_v1.types.ReadSession.TableModifiers):
        Optional. Any modifiers which are applied
        when reading from the specified table.
    read_options (google.cloud.bigquery_storage_v1.types.ReadSession.TableReadOptions):
        Optional. Read options for this session (e.g.
        column selection, filters).
    streams (Sequence[google.cloud.bigquery_storage_v1.types.ReadStream]):
        Output only. A list of streams created with the session.</p>
<pre><code>    At least one stream is created with the session. In the
    future, larger request_stream_count values *may* result in
    this list being unpopulated, in that case, the user will
    need to use a List method to get the streams instead, which
    is not yet available.
</code></pre></section>
        <h2><a class="xref" href="google.cloud.bigquery_storage_v1.types.ReadStream.html">ReadStream</a></h2>
        <section><p>Information about a single stream that gets data out of the storage
system. Most of the information about <code>ReadStream</code> instances is
aggregated, making <code>ReadStream</code> lightweight.</p>
<p>Attributes:
    name (str):
        Output only. Name of the stream, in the form
        <code>projects/{project_id}/locations/{location}/sessions/{session_id}/streams/{stream_id}</code>.</p>
</section>
        <h2><a class="xref" href="google.cloud.bigquery_storage_v1.types.SplitReadStreamRequest.html">SplitReadStreamRequest</a></h2>
        <section><p>Request message for <code>SplitReadStream</code>.
Attributes:
    name (str):
        Required. Name of the stream to split.
    fraction (float):
        A value in the range (0.0, 1.0) that
        specifies the fractional point at which the
        original stream should be split. The actual
        split point is evaluated on pre-filtered rows,
        so if a filter is provided, then there is no
        guarantee that the division of the rows between
        the new child streams will be proportional to
        this fractional value. Additionally, because the
        server-side unit for assigning data is
        collections of rows, this fraction will always
        map to a data storage boundary on the server
        side.</p>
</section>
        <h2><a class="xref" href="google.cloud.bigquery_storage_v1.types.SplitReadStreamResponse.html">SplitReadStreamResponse</a></h2>
        <section><p>Response message for <code>SplitReadStream</code>.
Attributes:
    primary_stream (google.cloud.bigquery_storage_v1.types.ReadStream):
        Primary stream, which contains the beginning portion of
        |original_stream|. An empty value indicates that the
        original stream can no longer be split.
    remainder_stream (google.cloud.bigquery_storage_v1.types.ReadStream):
        Remainder stream, which contains the tail of
        |original_stream|. An empty value indicates that the
        original stream can no longer be split.</p>
</section>
        <h2><a class="xref" href="google.cloud.bigquery_storage_v1.types.StreamStats.html">StreamStats</a></h2>
        <section><p>Estimated stream statistics for a given Stream.
Attributes:
    progress (google.cloud.bigquery_storage_v1.types.StreamStats.Progress):
        Represents the progress of the current
        stream.</p>
</section>
        <h2><a class="xref" href="google.cloud.bigquery_storage_v1.types.ThrottleState.html">ThrottleState</a></h2>
        <section><p>Information on if the current connection is being throttled.
Attributes:
    throttle_percent (int):
        How much this connection is being throttled.
        Zero means no throttling, 100 means fully
        throttled.</p>
</section>
</article>
    </div>
    {% endverbatim %}
  </body>
</html>
