<!DOCTYPE html>
<html devsite="">
  <head>
    <meta name="project_path" value="/python/_project.yaml">
    <meta name="book_path" value="/python/_book.yaml">
  </head>
  <body>
    {% verbatim %}
    <div>
      <article data-uid="google.cloud.bigquery_storage_v1.reader">
<h1 class="page-title">Module reader
</h1>
  
  
  <div class="markdown level0 summary"><p>API documentation for <code>reader</code> module.</p>
</div>
  <strong>Attributes</strong>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>google.cloud.bigquery_logging_v1.types.DatasetName</td>
        <td><em>dataset_name</em></td>
        <td>The name of the dataset.</td>
      </tr>
      <tr>
        <td>google.cloud.bigquery_logging_v1.types.DatasetInfo</td>
        <td><em>info</em></td>
        <td>User-provided metadata for the dataset.</td>
      </tr>
      <tr>
        <td>google.protobuf.timestamp_pb2.Timestamp</td>
        <td><em>create_time</em></td>
        <td>The time the dataset was created.</td>
      </tr>
      <tr>
        <td>google.protobuf.timestamp_pb2.Timestamp</td>
        <td><em>update_time</em></td>
        <td>The time the dataset was last modified.</td>
      </tr>
      <tr>
        <td>google.cloud.bigquery_logging_v1.types.BigQueryAcl</td>
        <td><em>acl</em></td>
        <td>The access control list for the dataset.</td>
      </tr>
      <tr>
        <td>google.protobuf.duration_pb2.Duration</td>
        <td><em>default_table_expire_duration</em></td>
        <td>If this field is present, each table that does not specify
   an expiration time is assigned an expiration time by adding
   this duration to the table's ``createTime``. If this field
   is empty, there is no default table expiration time.</td>
      </tr>
    </tbody>
  </table>
  <h2 id="classes">Classes
  </h2>
  <h3><a class="xref" href="google.cloud.bigquery_storage_v1.reader.ReadRowsIterable.html">ReadRowsIterable</a></h3>
  <div class="codewrapper">
    <pre class="prettyprint"><code>ReadRowsIterable(reader, read_session=None)</code></pre>
  </div>
  <div class="markdown level1 summary"><p>An iterable of rows from a read session.</p>
</div>
  <h3><a class="xref" href="google.cloud.bigquery_storage_v1.reader.ReadRowsPage.html">ReadRowsPage</a></h3>
  <div class="codewrapper">
    <pre class="prettyprint"><code>ReadRowsPage(stream_parser, message)</code></pre>
  </div>
  <div class="markdown level1 summary"><p>An iterator of rows from a read session message.</p>
</div>
  <h3><a class="xref" href="google.cloud.bigquery_storage_v1.reader.ReadRowsStream.html">ReadRowsStream</a></h3>
  <div class="codewrapper">
    <pre class="prettyprint"><code>ReadRowsStream(wrapped, client, name, offset, read_rows_kwargs)</code></pre>
  </div>
  <div class="markdown level1 summary"><p>A stream of results from a read rows request.</p>
<p>This stream is an iterable of
<a class="xref" href="google.cloud.bigquery_storage_v1.types.ReadRowsResponse.html">ReadRowsResponse</a>.
Iterate over it to fetch all row messages.</p>
<p>If the fastavro library is installed, use the
<a class="xref" href="google.cloud.bigquery_storage_v1.reader.ReadRowsStream.html">rows()</a>
method to parse all messages into a stream of row dictionaries.</p>
<p>If the pandas and fastavro libraries are installed, use the
<a class="xref" href="google.cloud.bigquery_storage_v1.reader.ReadRowsStream.html">to_dataframe()</a>
method to parse all messages into a <code>pandas.DataFrame</code>.</p>
</div>
</article>
    </div>
    {% endverbatim %}
  </body>
</html>
